#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŒå†™æœºåˆ¶çˆ¬è™«æµ‹è¯•è„šæœ¬
ä½¿ç”¨è¶…ä¿å®ˆè®¾ç½®è¿›è¡Œå°è§„æ¨¡çˆ¬å–æµ‹è¯•
"""

import os
import sys
import time
import subprocess
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

class DualWriteCrawlTest:
    """åŒå†™æœºåˆ¶çˆ¬è™«æµ‹è¯•"""
    
    def __init__(self):
        self.test_results = {}
        self.start_time = datetime.now()
    
    def create_conservative_spider_config(self):
        """åˆ›å»ºè¶…ä¿å®ˆçš„çˆ¬è™«é…ç½®"""
        
        # è¶…ä¿å®ˆçš„Scrapyè®¾ç½®
        conservative_settings = {
            'BOT_NAME': 'house_spider_dual_write_test',
            'SPIDER_MODULES': ['house_spider.spiders'],
            'NEWSPIDER_MODULE': 'house_spider.spiders',
            'ROBOTSTXT_OBEY': False,
            
            # è¶…çº§ä¿å®ˆçš„æ€§èƒ½è®¾ç½®
            'CONCURRENT_REQUESTS': 1,           # åªå…è®¸1ä¸ªå¹¶å‘è¯·æ±‚
            'CONCURRENT_REQUESTS_PER_DOMAIN': 1, # æ¯ä¸ªåŸŸå1ä¸ªè¯·æ±‚
            'DOWNLOAD_DELAY': 8,                # 8ç§’å»¶è¿Ÿ
            'RANDOMIZE_DOWNLOAD_DELAY': 1.0,    # éšæœºå»¶è¿Ÿ100%
            'AUTOTHROTTLE_ENABLED': True,       # å¯ç”¨è‡ªåŠ¨é™é€Ÿ
            'AUTOTHROTTLE_START_DELAY': 8,      # èµ·å§‹å»¶è¿Ÿ8ç§’
            'AUTOTHROTTLE_MAX_DELAY': 20,       # æœ€å¤§å»¶è¿Ÿ20ç§’
            'AUTOTHROTTLE_TARGET_CONCURRENCY': 0.3,  # ç›®æ ‡å¹¶å‘0.3
            'AUTOTHROTTLE_DEBUG': True,         # æ˜¾ç¤ºé™é€Ÿè°ƒè¯•ä¿¡æ¯
            
            # é‡è¯•è®¾ç½®
            'RETRY_TIMES': 2,
            'RETRY_HTTP_CODES': [500, 502, 503, 504, 408, 429, 403],
            'DOWNLOAD_TIMEOUT': 30,
            
            # è¯·æ±‚å¤´è®¾ç½®
            'DEFAULT_REQUEST_HEADERS': {
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                'Accept-Encoding': 'gzip, deflate',
                'Connection': 'keep-alive',
                'Cache-Control': 'no-cache',
                'Pragma': 'no-cache',
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            },
            
            # ä¸­é—´ä»¶ (åªå¯ç”¨å¿…è¦çš„)
            'DOWNLOADER_MIDDLEWARES': {
                'house_spider.middlewares.RotateUserAgentMiddleware': 400,
                'house_spider.middlewares.CustomRetryMiddleware': 550,
            },
            
            # åŒå†™æ•°æ®ç®¡é“
            'ITEM_PIPELINES': {
                'house_spider.pipelines.ValidationPipeline': 200,
                'mongodb_integration.pipelines.mongo_pipeline.DualWritePipeline': 300,
                'mongodb_integration.pipelines.mongo_pipeline.DataConsistencyPipeline': 400,
                'house_spider.pipelines.StatisticsPipeline': 500,
            },
            
            # æ—¥å¿—è®¾ç½®
            'LOG_LEVEL': 'INFO',
            'LOG_FILE': f'dual_write_test_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log',
            
            # MySQLé…ç½®
            'MYSQL_HOST': 'localhost',
            'MYSQL_PORT': 3306,
            'MYSQL_USER': 'root',
            'MYSQL_PASSWORD': '123456',
            'MYSQL_DATABASE': 'guangzhou_house',
            
            # MongoDBé…ç½®
            'MONGO_HOST': '127.0.0.1',
            'MONGO_PORT': 27017,
            'MONGO_DATABASE': 'house_data',
            
            # å†…å­˜ä½¿ç”¨ç›‘æ§
            'MEMUSAGE_ENABLED': True,
            'MEMUSAGE_LIMIT_MB': 1024,
            'MEMUSAGE_WARNING_MB': 512,
        }
        
        return conservative_settings
    
    def check_prerequisites(self):
        """æ£€æŸ¥æµ‹è¯•å‰ææ¡ä»¶"""
        print("ğŸ” æ£€æŸ¥æµ‹è¯•å‰ææ¡ä»¶...")
        
        # æ£€æŸ¥MongoDBçŠ¶æ€
        try:
            import pymongo
            client = pymongo.MongoClient('mongodb://127.0.0.1:27017/', serverSelectionTimeoutMS=2000)
            client.admin.command('ping')
            print("âœ… MongoDBè¿æ¥æ­£å¸¸")
            client.close()
        except Exception as e:
            print(f"âŒ MongoDBè¿æ¥å¤±è´¥: {e}")
            return False
        
        # æ£€æŸ¥MySQLçŠ¶æ€
        try:
            import pymysql
            conn = pymysql.connect(host='localhost', user='root', password='123456', database='guangzhou_house')
            cursor = conn.cursor()
            cursor.execute("SELECT 1")
            cursor.close()
            conn.close()
            print("âœ… MySQLè¿æ¥æ­£å¸¸")
        except Exception as e:
            print(f"âŒ MySQLè¿æ¥å¤±è´¥: {e}")
            return False
        
        # æ£€æŸ¥Scrapyé¡¹ç›®
        if not os.path.exists('scrapy_spider/house_spider'):
            print("âŒ Scrapyé¡¹ç›®ä¸å­˜åœ¨")
            return False
        print("âœ… Scrapyé¡¹ç›®å­˜åœ¨")
        
        # æ£€æŸ¥åŒå†™ç®¡é“
        if not os.path.exists('mongodb_integration/pipelines/mongo_pipeline.py'):
            print("âŒ åŒå†™ç®¡é“ä¸å­˜åœ¨")
            return False
        print("âœ… åŒå†™ç®¡é“å­˜åœ¨")
        
        return True
    
    def run_conservative_crawl(self, pages=1):
        """è¿è¡Œè¶…ä¿å®ˆçˆ¬è™«æµ‹è¯•"""
        print(f"\nğŸš€ å¼€å§‹åŒå†™æœºåˆ¶çˆ¬è™«æµ‹è¯• (çˆ¬å–{pages}é¡µ)...")
        print("âš ï¸  ä½¿ç”¨è¶…ä¿å®ˆè®¾ç½®ï¼š8ç§’å»¶è¿Ÿï¼Œå•å¹¶å‘ï¼Œæœ€å¤§20ç§’é™é€Ÿ")
        
        try:
            # åˆ‡æ¢åˆ°scrapyé¡¹ç›®ç›®å½•
            original_dir = os.getcwd()
            os.chdir('scrapy_spider')
            
            # æ„å»ºscrapyå‘½ä»¤
            cmd = [
                'scrapy', 'crawl', 'lianjia',
                '-a', f'pages={pages}',
                '-s', 'CONCURRENT_REQUESTS=1',
                '-s', 'DOWNLOAD_DELAY=8',
                '-s', 'RANDOMIZE_DOWNLOAD_DELAY=True',
                '-s', 'AUTOTHROTTLE_ENABLED=True',
                '-s', 'AUTOTHROTTLE_START_DELAY=8',
                '-s', 'AUTOTHROTTLE_MAX_DELAY=20',
                '-s', 'AUTOTHROTTLE_TARGET_CONCURRENCY=0.3',
                '-s', 'AUTOTHROTTLE_DEBUG=True',
                '-s', 'RETRY_TIMES=2',
                '-s', 'DOWNLOAD_TIMEOUT=30',
                '-s', 'LOG_LEVEL=INFO',
                # é…ç½®åŒå†™ç®¡é“
                '-s', 'ITEM_PIPELINES={"house_spider.pipelines.ValidationPipeline": 200, "mongodb_integration.pipelines.mongo_pipeline.DualWritePipeline": 300, "mongodb_integration.pipelines.mongo_pipeline.DataConsistencyPipeline": 400, "house_spider.pipelines.StatisticsPipeline": 500}',
                # MongoDBé…ç½®
                '-s', 'MONGO_HOST=127.0.0.1',
                '-s', 'MONGO_PORT=27017',
                '-s', 'MONGO_DATABASE=house_data'
            ]
            
            print(f"æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
            
            # è¿è¡Œçˆ¬è™«
            start_time = time.time()
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=600)  # 10åˆ†é’Ÿè¶…æ—¶
            crawl_time = time.time() - start_time
            
            # åˆ‡æ¢å›åŸç›®å½•
            os.chdir(original_dir)
            
            # åˆ†æç»“æœ
            if result.returncode == 0:
                print(f"âœ… çˆ¬è™«æ‰§è¡ŒæˆåŠŸ")
                print(f"â±ï¸  æ‰§è¡Œæ—¶é—´: {crawl_time:.1f} ç§’")
                
                # åˆ†ææ—¥å¿—è¾“å‡º
                output = result.stdout + result.stderr
                
                # æå–ç»Ÿè®¡ä¿¡æ¯
                stats = self.extract_crawl_stats(output)
                
                self.test_results['crawl_test'] = {
                    'success': True,
                    'crawl_time': crawl_time,
                    'pages_requested': pages,
                    'stats': stats
                }
                
                print(f"ğŸ“Š çˆ¬å–ç»Ÿè®¡:")
                for key, value in stats.items():
                    print(f"  {key}: {value}")
                
                return True
                
            else:
                print(f"âŒ çˆ¬è™«æ‰§è¡Œå¤±è´¥ (è¿”å›ç : {result.returncode})")
                print(f"é”™è¯¯è¾“å‡º: {result.stderr}")
                
                self.test_results['crawl_test'] = {
                    'success': False,
                    'error': result.stderr,
                    'return_code': result.returncode
                }
                
                return False
                
        except subprocess.TimeoutExpired:
            print("âŒ çˆ¬è™«æ‰§è¡Œè¶…æ—¶")
            os.chdir(original_dir)
            return False
        except Exception as e:
            print(f"âŒ çˆ¬è™«æ‰§è¡Œå¼‚å¸¸: {e}")
            os.chdir(original_dir)
            return False
    
    def extract_crawl_stats(self, output):
        """ä»çˆ¬è™«è¾“å‡ºä¸­æå–ç»Ÿè®¡ä¿¡æ¯"""
        stats = {}
        
        lines = output.split('\n')
        for line in lines:
            if 'item_scraped_count' in line:
                try:
                    count = int(line.split(':')[-1].strip())
                    stats['çˆ¬å–æ¡æ•°'] = count
                except:
                    pass
            elif 'request_count' in line:
                try:
                    count = int(line.split(':')[-1].strip())
                    stats['è¯·æ±‚æ•°'] = count
                except:
                    pass
            elif 'response_received_count' in line:
                try:
                    count = int(line.split(':')[-1].strip())
                    stats['å“åº”æ•°'] = count
                except:
                    pass
            elif 'downloader/exception_count' in line:
                try:
                    count = int(line.split(':')[-1].strip())
                    stats['å¼‚å¸¸æ•°'] = count
                except:
                    pass
        
        return stats
    
    def verify_dual_write_results(self):
        """éªŒè¯åŒå†™ç»“æœ"""
        print("\nğŸ” éªŒè¯åŒå†™ç»“æœ...")
        
        try:
            import pymysql
            import mongoengine
            from mongodb_integration.models.mongo_models import HouseDocument
            
            # è¿æ¥æ•°æ®åº“
            mysql_conn = pymysql.connect(host='localhost', user='root', password='123456', database='guangzhou_house')
            mongoengine.connect('house_data', host='127.0.0.1', port=27017)
            
            # æ£€æŸ¥MySQLåŒå†™è¡¨
            cursor = mysql_conn.cursor()
            cursor.execute("SELECT COUNT(*) FROM House_dual_write")
            mysql_count = cursor.fetchone()[0]
            
            # æ£€æŸ¥MongoDB
            mongo_count = HouseDocument.objects(crawl_meta__spider_name='lianjia').count()
            
            cursor.close()
            mysql_conn.close()
            mongoengine.disconnect()
            
            print(f"ğŸ“Š åŒå†™ç»“æœ:")
            print(f"  MySQLåŒå†™è¡¨: {mysql_count} æ¡")
            print(f"  MongoDBæ–°å¢: {mongo_count} æ¡")
            
            # åˆ¤æ–­åŒå†™æ˜¯å¦æˆåŠŸ
            if mysql_count > 0 and mongo_count > 0:
                print("âœ… åŒå†™æœºåˆ¶å·¥ä½œæ­£å¸¸")
                success_rate = min(mysql_count, mongo_count) / max(mysql_count, mongo_count) * 100
                print(f"ğŸ“ˆ æ•°æ®ä¸€è‡´æ€§: {success_rate:.1f}%")
                
                self.test_results['dual_write_verification'] = {
                    'success': True,
                    'mysql_count': mysql_count,
                    'mongo_count': mongo_count,
                    'consistency_rate': success_rate
                }
                
                return True
            else:
                print("âŒ åŒå†™æœºåˆ¶å¯èƒ½å­˜åœ¨é—®é¢˜")
                self.test_results['dual_write_verification'] = {
                    'success': False,
                    'mysql_count': mysql_count,
                    'mongo_count': mongo_count
                }
                return False
                
        except Exception as e:
            print(f"âŒ åŒå†™éªŒè¯å¤±è´¥: {e}")
            return False
    
    def generate_report(self):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        print("\n" + "="*60)
        print("ğŸ“‹ åŒå†™æœºåˆ¶çˆ¬è™«æµ‹è¯•æŠ¥å‘Š")
        print("="*60)
        
        total_time = (datetime.now() - self.start_time).total_seconds()
        print(f"â±ï¸  æ€»æµ‹è¯•æ—¶é—´: {total_time:.1f} ç§’")
        print(f"ğŸ“… æµ‹è¯•æ—¶é—´: {self.start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        
        # çˆ¬è™«æµ‹è¯•ç»“æœ
        if 'crawl_test' in self.test_results:
            crawl_result = self.test_results['crawl_test']
            if crawl_result['success']:
                print(f"\nğŸš€ çˆ¬è™«æµ‹è¯•ç»“æœ: âœ… æˆåŠŸ")
                print(f"  - æ‰§è¡Œæ—¶é—´: {crawl_result['crawl_time']:.1f} ç§’")
                if 'stats' in crawl_result:
                    for key, value in crawl_result['stats'].items():
                        print(f"  - {key}: {value}")
            else:
                print(f"\nğŸš€ çˆ¬è™«æµ‹è¯•ç»“æœ: âŒ å¤±è´¥")
                print(f"  - é”™è¯¯: {crawl_result.get('error', 'Unknown error')}")
        
        # åŒå†™éªŒè¯ç»“æœ
        if 'dual_write_verification' in self.test_results:
            verify_result = self.test_results['dual_write_verification']
            if verify_result['success']:
                print(f"\nğŸ” åŒå†™éªŒè¯ç»“æœ: âœ… æˆåŠŸ")
                print(f"  - MySQLè®°å½•: {verify_result['mysql_count']} æ¡")
                print(f"  - MongoDBè®°å½•: {verify_result['mongo_count']} æ¡")
                print(f"  - ä¸€è‡´æ€§: {verify_result['consistency_rate']:.1f}%")
            else:
                print(f"\nğŸ” åŒå†™éªŒè¯ç»“æœ: âŒ å¤±è´¥")
                print(f"  - MySQLè®°å½•: {verify_result['mysql_count']} æ¡")
                print(f"  - MongoDBè®°å½•: {verify_result['mongo_count']} æ¡")
        
        print("\n" + "="*60)

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ åŒå†™æœºåˆ¶çˆ¬è™«æµ‹è¯•å¥—ä»¶")
    print("="*60)
    
    # åˆ›å»ºæµ‹è¯•å¥—ä»¶
    test_suite = DualWriteCrawlTest()
    
    try:
        # 1. æ£€æŸ¥å‰ææ¡ä»¶
        if not test_suite.check_prerequisites():
            print("âŒ å‰ææ¡ä»¶æ£€æŸ¥å¤±è´¥ï¼Œæ— æ³•ç»§ç»­æµ‹è¯•")
            return False
        
        # 2. è¿è¡Œä¿å®ˆçˆ¬è™«æµ‹è¯• (åªçˆ¬å–1é¡µï¼Œçº¦20æ¡æ•°æ®)
        if not test_suite.run_conservative_crawl(pages=1):
            print("âŒ çˆ¬è™«æµ‹è¯•å¤±è´¥")
            return False
        
        # 3. éªŒè¯åŒå†™ç»“æœ
        test_suite.verify_dual_write_results()
        
        # 4. ç”ŸæˆæŠ¥å‘Š
        test_suite.generate_report()
        
        print("\nğŸ‰ åŒå†™æœºåˆ¶çˆ¬è™«æµ‹è¯•å®Œæˆï¼")
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        return False

if __name__ == '__main__':
    success = main()
    sys.exit(0 if success else 1)
