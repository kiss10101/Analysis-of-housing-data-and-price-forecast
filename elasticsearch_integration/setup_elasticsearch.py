#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Elasticsearchåˆ†å¸ƒå¼é›†ç¾¤å®‰è£…å’Œé…ç½®è„šæœ¬
æˆ¿æºæ•°æ®åˆ†æç³»ç»Ÿ - å¤§æ•°æ®å­˜å‚¨æ–¹æ¡ˆéƒ¨ç½²
"""

import os
import sys
import subprocess
import time
import requests
import json
import logging
from pathlib import Path

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ElasticsearchSetup:
    """Elasticsearchå®‰è£…é…ç½®ç±»"""
    
    def __init__(self):
        self.es_version = "7.17.0"  # ä½¿ç”¨ç¨³å®šç‰ˆæœ¬
        self.base_dir = Path("elasticsearch_cluster")
        self.nodes = [
            {"name": "node-1", "port": 9200, "transport_port": 9300},
            {"name": "node-2", "port": 9201, "transport_port": 9301},
            {"name": "node-3", "port": 9202, "transport_port": 9302}
        ]
        self.cluster_name = "house-data-cluster"
    
    def download_elasticsearch(self):
        """ä¸‹è½½Elasticsearch"""
        logger.info("å¼€å§‹ä¸‹è½½Elasticsearch...")
        
        # åˆ›å»ºç›®å½•
        self.base_dir.mkdir(exist_ok=True)
        
        # æ£€æŸ¥æ˜¯å¦å·²ä¸‹è½½
        es_archive = self.base_dir / f"elasticsearch-{self.es_version}-windows-x86_64.zip"
        if es_archive.exists():
            logger.info("Elasticsearchå·²ä¸‹è½½ï¼Œè·³è¿‡ä¸‹è½½æ­¥éª¤")
            return True
        
        # ä¸‹è½½URL
        download_url = f"https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-{self.es_version}-windows-x86_64.zip"
        
        try:
            import urllib.request
            logger.info(f"æ­£åœ¨ä¸‹è½½: {download_url}")
            urllib.request.urlretrieve(download_url, es_archive)
            logger.info("âœ… Elasticsearchä¸‹è½½å®Œæˆ")
            return True
        except Exception as e:
            logger.error(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
            logger.info("è¯·æ‰‹åŠ¨ä¸‹è½½Elasticsearchå¹¶æ”¾ç½®åœ¨elasticsearch_clusterç›®å½•ä¸‹")
            return False
    
    def extract_elasticsearch(self):
        """è§£å‹Elasticsearch"""
        logger.info("å¼€å§‹è§£å‹Elasticsearch...")
        
        es_archive = self.base_dir / f"elasticsearch-{self.es_version}-windows-x86_64.zip"
        if not es_archive.exists():
            logger.error("Elasticsearchå‹ç¼©åŒ…ä¸å­˜åœ¨")
            return False
        
        try:
            import zipfile
            with zipfile.ZipFile(es_archive, 'r') as zip_ref:
                zip_ref.extractall(self.base_dir)
            
            logger.info("âœ… Elasticsearchè§£å‹å®Œæˆ")
            return True
        except Exception as e:
            logger.error(f"âŒ è§£å‹å¤±è´¥: {e}")
            return False
    
    def create_node_configs(self):
        """åˆ›å»ºèŠ‚ç‚¹é…ç½®æ–‡ä»¶"""
        logger.info("åˆ›å»ºèŠ‚ç‚¹é…ç½®æ–‡ä»¶...")
        
        es_home = self.base_dir / f"elasticsearch-{self.es_version}"
        
        for i, node in enumerate(self.nodes):
            node_dir = self.base_dir / node["name"]
            node_dir.mkdir(exist_ok=True)
            
            # åˆ›å»ºæ•°æ®å’Œæ—¥å¿—ç›®å½•
            (node_dir / "data").mkdir(exist_ok=True)
            (node_dir / "logs").mkdir(exist_ok=True)
            
            # ç”Ÿæˆé…ç½®æ–‡ä»¶
            config_content = self.generate_node_config(node, i == 0)
            
            config_file = node_dir / "elasticsearch.yml"
            with open(config_file, 'w', encoding='utf-8') as f:
                f.write(config_content)
            
            logger.info(f"âœ… èŠ‚ç‚¹ {node['name']} é…ç½®åˆ›å»ºå®Œæˆ")
        
        return True
    
    def generate_node_config(self, node, is_master=False):
        """ç”ŸæˆèŠ‚ç‚¹é…ç½®"""
        config = f"""# Elasticsearché…ç½®æ–‡ä»¶ - {node['name']}
# é›†ç¾¤é…ç½®
cluster.name: {self.cluster_name}
node.name: {node['name']}

# èŠ‚ç‚¹è§’è‰²
node.master: {"true" if is_master else "false"}
node.data: true
node.ingest: true

# ç½‘ç»œé…ç½®
network.host: 127.0.0.1
http.port: {node['port']}
transport.tcp.port: {node['transport_port']}

# å‘ç°é…ç½®
discovery.seed_hosts: ["127.0.0.1:9300", "127.0.0.1:9301", "127.0.0.1:9302"]
cluster.initial_master_nodes: ["node-1"]

# è·¯å¾„é…ç½®
path.data: {self.base_dir.absolute() / node['name'] / 'data'}
path.logs: {self.base_dir.absolute() / node['name'] / 'logs'}

# å†…å­˜é…ç½®
bootstrap.memory_lock: false

# å®‰å…¨é…ç½®ï¼ˆå¼€å‘ç¯å¢ƒï¼‰
xpack.security.enabled: false
xpack.monitoring.collection.enabled: false

# æ€§èƒ½é…ç½®
indices.query.bool.max_clause_count: 10000
search.max_buckets: 65536

# åˆ†ç‰‡é…ç½®
cluster.max_shards_per_node: 3000
"""
        return config
    
    def create_startup_scripts(self):
        """åˆ›å»ºå¯åŠ¨è„šæœ¬"""
        logger.info("åˆ›å»ºå¯åŠ¨è„šæœ¬...")
        
        es_home = self.base_dir / f"elasticsearch-{self.es_version}"
        
        # åˆ›å»ºå•èŠ‚ç‚¹å¯åŠ¨è„šæœ¬
        for node in self.nodes:
            script_content = f"""@echo off
echo å¯åŠ¨ElasticsearchèŠ‚ç‚¹: {node['name']}
cd /d "{es_home.absolute()}"
set ES_PATH_CONF={self.base_dir.absolute() / node['name']}
bin\\elasticsearch.bat
pause
"""
            script_file = self.base_dir / f"start_{node['name']}.bat"
            with open(script_file, 'w', encoding='utf-8') as f:
                f.write(script_content)
        
        # åˆ›å»ºé›†ç¾¤å¯åŠ¨è„šæœ¬
        cluster_script = """@echo off
echo å¯åŠ¨Elasticsearché›†ç¾¤...
echo.

echo å¯åŠ¨èŠ‚ç‚¹1 (ä¸»èŠ‚ç‚¹)...
start "ES-Node-1" cmd /c "start_node-1.bat"
timeout /t 10

echo å¯åŠ¨èŠ‚ç‚¹2...
start "ES-Node-2" cmd /c "start_node-2.bat"
timeout /t 5

echo å¯åŠ¨èŠ‚ç‚¹3...
start "ES-Node-3" cmd /c "start_node-3.bat"

echo.
echo é›†ç¾¤å¯åŠ¨å®Œæˆï¼
echo ç­‰å¾…30ç§’åæ£€æŸ¥é›†ç¾¤çŠ¶æ€...
timeout /t 30

echo æ£€æŸ¥é›†ç¾¤çŠ¶æ€:
curl -X GET "localhost:9200/_cluster/health?pretty"
pause
"""
        
        cluster_script_file = self.base_dir / "start_cluster.bat"
        with open(cluster_script_file, 'w', encoding='utf-8') as f:
            f.write(cluster_script)
        
        # åˆ›å»ºåœæ­¢è„šæœ¬
        stop_script = """@echo off
echo åœæ­¢Elasticsearché›†ç¾¤...
taskkill /f /im java.exe /fi "WINDOWTITLE eq ES-*"
echo é›†ç¾¤å·²åœæ­¢
pause
"""
        
        stop_script_file = self.base_dir / "stop_cluster.bat"
        with open(stop_script_file, 'w', encoding='utf-8') as f:
            f.write(stop_script)
        
        logger.info("âœ… å¯åŠ¨è„šæœ¬åˆ›å»ºå®Œæˆ")
        return True
    
    def install_ik_analyzer(self):
        """å®‰è£…IKä¸­æ–‡åˆ†è¯å™¨"""
        logger.info("å®‰è£…IKä¸­æ–‡åˆ†è¯å™¨...")
        
        es_home = self.base_dir / f"elasticsearch-{self.es_version}"
        plugins_dir = es_home / "plugins" / "ik"
        plugins_dir.mkdir(parents=True, exist_ok=True)
        
        # IKåˆ†è¯å™¨ä¸‹è½½URL
        ik_url = f"https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v{self.es_version}/elasticsearch-analysis-ik-{self.es_version}.zip"
        
        try:
            import urllib.request
            ik_archive = self.base_dir / f"elasticsearch-analysis-ik-{self.es_version}.zip"
            
            if not ik_archive.exists():
                logger.info(f"ä¸‹è½½IKåˆ†è¯å™¨: {ik_url}")
                urllib.request.urlretrieve(ik_url, ik_archive)
            
            # è§£å‹åˆ°pluginsç›®å½•
            import zipfile
            with zipfile.ZipFile(ik_archive, 'r') as zip_ref:
                zip_ref.extractall(plugins_dir)
            
            logger.info("âœ… IKä¸­æ–‡åˆ†è¯å™¨å®‰è£…å®Œæˆ")
            return True
            
        except Exception as e:
            logger.warning(f"âš ï¸ IKåˆ†è¯å™¨å®‰è£…å¤±è´¥: {e}")
            logger.info("å¯ä»¥æ‰‹åŠ¨å®‰è£…IKåˆ†è¯å™¨ä»¥æ”¯æŒä¸­æ–‡æœç´¢")
            return False
    
    def create_test_script(self):
        """åˆ›å»ºæµ‹è¯•è„šæœ¬"""
        test_script = """@echo off
echo æµ‹è¯•Elasticsearché›†ç¾¤...
echo.

echo 1. æ£€æŸ¥é›†ç¾¤å¥åº·çŠ¶æ€:
curl -X GET "localhost:9200/_cluster/health?pretty"
echo.

echo 2. æ£€æŸ¥èŠ‚ç‚¹ä¿¡æ¯:
curl -X GET "localhost:9200/_nodes?pretty"
echo.

echo 3. åˆ›å»ºæµ‹è¯•ç´¢å¼•:
curl -X PUT "localhost:9200/test_index" -H "Content-Type: application/json" -d "{\\"settings\\": {\\"number_of_shards\\": 3, \\"number_of_replicas\\": 1}}"
echo.

echo 4. æ£€æŸ¥ç´¢å¼•çŠ¶æ€:
curl -X GET "localhost:9200/_cat/indices?v"
echo.

echo 5. åˆ é™¤æµ‹è¯•ç´¢å¼•:
curl -X DELETE "localhost:9200/test_index"
echo.

echo æµ‹è¯•å®Œæˆï¼
pause
"""
        
        test_script_file = self.base_dir / "test_cluster.bat"
        with open(test_script_file, 'w', encoding='utf-8') as f:
            f.write(test_script)
        
        logger.info("âœ… æµ‹è¯•è„šæœ¬åˆ›å»ºå®Œæˆ")
    
    def create_readme(self):
        """åˆ›å»ºè¯´æ˜æ–‡æ¡£"""
        readme_content = f"""# Elasticsearchåˆ†å¸ƒå¼é›†ç¾¤éƒ¨ç½²æŒ‡å—

## é›†ç¾¤é…ç½®
- é›†ç¾¤åç§°: {self.cluster_name}
- Elasticsearchç‰ˆæœ¬: {self.es_version}
- èŠ‚ç‚¹æ•°é‡: 3ä¸ªèŠ‚ç‚¹
- åˆ†ç‰‡é…ç½®: 3ä¸ªä¸»åˆ†ç‰‡ï¼Œ1ä¸ªå‰¯æœ¬åˆ†ç‰‡

## èŠ‚ç‚¹ä¿¡æ¯
"""
        for node in self.nodes:
            readme_content += f"- {node['name']}: HTTPç«¯å£ {node['port']}, ä¼ è¾“ç«¯å£ {node['transport_port']}\n"
        
        readme_content += """
## å¯åŠ¨æ­¥éª¤
1. è¿è¡Œ `start_cluster.bat` å¯åŠ¨æ•´ä¸ªé›†ç¾¤
2. ç­‰å¾…æ‰€æœ‰èŠ‚ç‚¹å¯åŠ¨å®Œæˆï¼ˆçº¦30-60ç§’ï¼‰
3. è¿è¡Œ `test_cluster.bat` æµ‹è¯•é›†ç¾¤çŠ¶æ€

## å•èŠ‚ç‚¹å¯åŠ¨
å¦‚æœéœ€è¦å•ç‹¬å¯åŠ¨èŠ‚ç‚¹ï¼š
- è¿è¡Œ `start_node-1.bat` å¯åŠ¨ä¸»èŠ‚ç‚¹
- è¿è¡Œ `start_node-2.bat` å¯åŠ¨æ•°æ®èŠ‚ç‚¹2
- è¿è¡Œ `start_node-3.bat` å¯åŠ¨æ•°æ®èŠ‚ç‚¹3

## åœæ­¢é›†ç¾¤
è¿è¡Œ `stop_cluster.bat` åœæ­¢æ‰€æœ‰èŠ‚ç‚¹

## è®¿é—®åœ°å€
- ä¸»èŠ‚ç‚¹: http://localhost:9200
- èŠ‚ç‚¹2: http://localhost:9201
- èŠ‚ç‚¹3: http://localhost:9202

## é›†ç¾¤ç®¡ç†
- é›†ç¾¤å¥åº·: GET /_cluster/health
- èŠ‚ç‚¹ä¿¡æ¯: GET /_nodes
- ç´¢å¼•çŠ¶æ€: GET /_cat/indices?v
- åˆ†ç‰‡ä¿¡æ¯: GET /_cat/shards?v

## æ³¨æ„äº‹é¡¹
1. ç¡®ä¿Java 8+å·²å®‰è£…
2. ç¡®ä¿ç«¯å£9200-9202å’Œ9300-9302æœªè¢«å ç”¨
3. é¦–æ¬¡å¯åŠ¨å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´
4. å¦‚æœå¯åŠ¨å¤±è´¥ï¼Œæ£€æŸ¥logsç›®å½•ä¸‹çš„æ—¥å¿—æ–‡ä»¶

## æ•°æ®è¿ç§»
ä½¿ç”¨Pythonè„šæœ¬è¿›è¡Œæ•°æ®è¿ç§»ï¼š
```bash
python data_migration.py
```

## Djangoé›†æˆ
åœ¨Djangoé¡¹ç›®ä¸­æ·»åŠ Elasticsearchæ”¯æŒï¼š
```python
from elasticsearch_integration.django_integration import get_elasticsearch_urls
```
"""
        
        readme_file = self.base_dir / "README.md"
        with open(readme_file, 'w', encoding='utf-8') as f:
            f.write(readme_content)
        
        logger.info("âœ… è¯´æ˜æ–‡æ¡£åˆ›å»ºå®Œæˆ")
    
    def setup_complete(self):
        """å®Œæˆå®‰è£…"""
        logger.info("ğŸ‰ Elasticsearchåˆ†å¸ƒå¼é›†ç¾¤å®‰è£…å®Œæˆï¼")
        logger.info(f"ğŸ“ å®‰è£…ç›®å½•: {self.base_dir.absolute()}")
        logger.info("ğŸ“‹ ä¸‹ä¸€æ­¥æ“ä½œ:")
        logger.info("   1. è¿›å…¥elasticsearch_clusterç›®å½•")
        logger.info("   2. è¿è¡Œstart_cluster.batå¯åŠ¨é›†ç¾¤")
        logger.info("   3. è¿è¡Œtest_cluster.batæµ‹è¯•é›†ç¾¤")
        logger.info("   4. è¿è¡ŒPythonæ•°æ®è¿ç§»è„šæœ¬")
        logger.info("ğŸ”— è®¿é—®åœ°å€: http://localhost:9200")

def main():
    """ä¸»å‡½æ•°"""
    setup = ElasticsearchSetup()
    
    logger.info("å¼€å§‹å®‰è£…Elasticsearchåˆ†å¸ƒå¼é›†ç¾¤...")
    
    # æ‰§è¡Œå®‰è£…æ­¥éª¤
    steps = [
        ("ä¸‹è½½Elasticsearch", setup.download_elasticsearch),
        ("è§£å‹Elasticsearch", setup.extract_elasticsearch),
        ("åˆ›å»ºèŠ‚ç‚¹é…ç½®", setup.create_node_configs),
        ("åˆ›å»ºå¯åŠ¨è„šæœ¬", setup.create_startup_scripts),
        ("å®‰è£…IKåˆ†è¯å™¨", setup.install_ik_analyzer),
        ("åˆ›å»ºæµ‹è¯•è„šæœ¬", setup.create_test_script),
        ("åˆ›å»ºè¯´æ˜æ–‡æ¡£", setup.create_readme)
    ]
    
    for step_name, step_func in steps:
        logger.info(f"æ‰§è¡Œæ­¥éª¤: {step_name}")
        if not step_func():
            logger.error(f"æ­¥éª¤å¤±è´¥: {step_name}")
            return False
    
    setup.setup_complete()
    return True

if __name__ == '__main__':
    main()
