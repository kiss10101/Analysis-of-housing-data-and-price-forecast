#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
ç»¼åˆæµ‹è¯•è¿è¡Œè„šæœ¬
è¿è¡Œæ‰€æœ‰æŠ€æœ¯éªŒè¯æµ‹è¯•å¹¶ç”Ÿæˆç»¼åˆæŠ¥å‘Š
"""

import os
import sys
import json
import subprocess
from datetime import datetime


def run_test_script(script_path, test_name):
    """è¿è¡Œæµ‹è¯•è„šæœ¬"""
    print(f"\n{'='*60}")
    print(f"ğŸš€ å¼€å§‹è¿è¡Œ: {test_name}")
    print(f"{'='*60}")
    
    try:
        result = subprocess.run([
            sys.executable, script_path
        ], capture_output=True, text=True, timeout=600)
        
        print(f"âœ… {test_name} å®Œæˆ")
        print(f"è¿”å›ç : {result.returncode}")
        
        if result.stdout:
            print("è¾“å‡º:")
            print(result.stdout[-1000:])  # æ˜¾ç¤ºæœ€å1000å­—ç¬¦
        
        if result.stderr and result.returncode != 0:
            print("é”™è¯¯:")
            print(result.stderr[-500:])  # æ˜¾ç¤ºæœ€å500å­—ç¬¦
        
        return {
            'success': result.returncode == 0,
            'return_code': result.returncode,
            'stdout': result.stdout,
            'stderr': result.stderr
        }
        
    except subprocess.TimeoutExpired:
        print(f"âŒ {test_name} è¶…æ—¶")
        return {
            'success': False,
            'error': 'timeout'
        }
    except Exception as e:
        print(f"âŒ {test_name} æ‰§è¡Œå¤±è´¥: {e}")
        return {
            'success': False,
            'error': str(e)
        }


def generate_comprehensive_report(test_results):
    """ç”Ÿæˆç»¼åˆæŠ¥å‘Š"""
    print("\nğŸ“Š ç”Ÿæˆç»¼åˆæµ‹è¯•æŠ¥å‘Š...")
    
    # åˆ›å»ºæŠ¥å‘Šç›®å½•
    report_dir = os.path.join(os.path.dirname(__file__), 'reports')
    os.makedirs(report_dir, exist_ok=True)
    
    # ç»¼åˆç»“æœ
    comprehensive_results = {
        'test_time': datetime.now().isoformat(),
        'test_results': test_results,
        'summary': {
            'total_tests': len(test_results),
            'passed_tests': sum(1 for r in test_results.values() if r.get('success')),
            'failed_tests': sum(1 for r in test_results.values() if not r.get('success'))
        }
    }
    
    # è¯»å–å„ä¸ªæµ‹è¯•çš„è¯¦ç»†æŠ¥å‘Š
    detailed_reports = {}
    
    # æ€§èƒ½å¯¹æ¯”æŠ¥å‘Š
    perf_report_file = os.path.join(report_dir, 'performance_comparison.json')
    if os.path.exists(perf_report_file):
        try:
            with open(perf_report_file, 'r', encoding='utf-8') as f:
                detailed_reports['performance'] = json.load(f)
        except:
            pass
    
    # MongoDBé›†æˆæŠ¥å‘Š
    mongo_report_file = os.path.join(report_dir, 'mongodb_integration_test.json')
    if os.path.exists(mongo_report_file):
        try:
            with open(mongo_report_file, 'r', encoding='utf-8') as f:
                detailed_reports['mongodb'] = json.load(f)
        except:
            pass
    
    # æ•°æ®è¿ç§»æŠ¥å‘Š
    migration_report_file = os.path.join(report_dir, 'data_migration_test.json')
    if os.path.exists(migration_report_file):
        try:
            with open(migration_report_file, 'r', encoding='utf-8') as f:
                detailed_reports['migration'] = json.load(f)
        except:
            pass
    
    comprehensive_results['detailed_reports'] = detailed_reports
    
    # ä¿å­˜JSONæŠ¥å‘Š
    json_file = os.path.join(report_dir, 'comprehensive_test_report.json')
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump(comprehensive_results, f, ensure_ascii=False, indent=2)
    
    # ç”ŸæˆMarkdownæŠ¥å‘Š
    md_content = generate_markdown_summary(comprehensive_results)
    md_file = os.path.join(report_dir, 'comprehensive_test_report.md')
    with open(md_file, 'w', encoding='utf-8') as f:
        f.write(md_content)
    
    print(f"ğŸ“„ ç»¼åˆæŠ¥å‘Šå·²ç”Ÿæˆ: {md_file}")
    return md_file


def generate_markdown_summary(results):
    """ç”ŸæˆMarkdownç»¼åˆæŠ¥å‘Š"""
    test_results = results['test_results']
    summary = results['summary']
    detailed = results.get('detailed_reports', {})
    
    # åŸºæœ¬ä¿¡æ¯
    md = f"""# æ¶æ„å‡çº§æŠ€æœ¯éªŒè¯ç»¼åˆæŠ¥å‘Š

## æµ‹è¯•æ¦‚è§ˆ
- **æµ‹è¯•æ—¶é—´**: {results['test_time']}
- **æ€»æµ‹è¯•æ•°**: {summary['total_tests']}
- **é€šè¿‡æµ‹è¯•**: {summary['passed_tests']} âœ…
- **å¤±è´¥æµ‹è¯•**: {summary['failed_tests']} âŒ
- **æˆåŠŸç‡**: {(summary['passed_tests']/summary['total_tests']*100):.1f}%

## æµ‹è¯•ç»“æœè¯¦æƒ…

"""
    
    # å„é¡¹æµ‹è¯•ç»“æœ
    for test_name, result in test_results.items():
        status = "âœ… é€šè¿‡" if result.get('success') else "âŒ å¤±è´¥"
        md += f"### {test_name}\n"
        md += f"- **çŠ¶æ€**: {status}\n"
        if not result.get('success') and result.get('error'):
            md += f"- **é”™è¯¯**: {result['error']}\n"
        md += "\n"
    
    # æ€§èƒ½å¯¹æ¯”åˆ†æ
    if 'performance' in detailed:
        perf = detailed['performance']
        original = perf.get('original_crawler', {})
        scrapy = perf.get('scrapy_crawler', {})
        comparison = perf.get('comparison', {})
        
        md += f"""## æ€§èƒ½å¯¹æ¯”åˆ†æ

### çˆ¬è™«æ€§èƒ½å¯¹æ¯”
| æŒ‡æ ‡ | åŸå§‹çˆ¬è™« | Scrapyçˆ¬è™« | æ”¹è¿› |
|------|----------|------------|------|
| æŠ“å–é€Ÿåº¦ | {original.get('items_per_second', 0):.2f} æ¡/ç§’ | {scrapy.get('items_per_second', 0):.2f} æ¡/ç§’ | {comparison.get('speed_improvement', 0):.1f}% |
| æ€»è€—æ—¶ | {original.get('total_time', 0):.2f} ç§’ | {scrapy.get('total_time', 0):.2f} ç§’ | {comparison.get('time_difference', 0):.2f} ç§’ |
| å†…å­˜ä½¿ç”¨ | {original.get('memory_usage', 0):.2f} MB | {scrapy.get('memory_usage', 0):.2f} MB | {comparison.get('memory_difference', 0):.2f} MB |
| é”™è¯¯æ•°é‡ | {original.get('errors', 0)} | {scrapy.get('errors', 0)} | {comparison.get('reliability_improvement', 0):.1f}% |

"""
    
    # MongoDBé›†æˆåˆ†æ
    if 'mongodb' in detailed:
        mongo = detailed['mongodb']
        conn = mongo.get('connection_test', {})
        crud = mongo.get('crud_test', {})
        perf = mongo.get('performance_test', {})
        
        md += f"""## MongoDBé›†æˆåˆ†æ

### è¿æ¥æ€§èƒ½
- **è¿æ¥æ—¶é—´**: {conn.get('connection_time', 0):.3f} ç§’
- **MongoDBç‰ˆæœ¬**: {conn.get('server_info', 'N/A')}

### CRUDæ€§èƒ½
- **æ’å…¥æ€§èƒ½**: {crud.get('insert_time', 0):.3f} ç§’
- **æŸ¥è¯¢æ€§èƒ½**: {crud.get('query_time', 0):.3f} ç§’
- **èšåˆæŸ¥è¯¢**: {crud.get('aggregation_time', 0):.3f} ç§’

### æ‰¹é‡æ“ä½œæ€§èƒ½
- **æ’å…¥é€Ÿåº¦**: {perf.get('insert_rate', 0):.0f} æ¡/ç§’
- **æµ‹è¯•è®°å½•æ•°**: {perf.get('record_count', 0)} æ¡

"""
    
    # æ•°æ®è¿ç§»åˆ†æ
    if 'migration' in detailed:
        migration = detailed['migration']
        extract = migration.get('data_extraction', {})
        load = migration.get('data_loading', {})
        validate = migration.get('validation', {})
        
        md += f"""## æ•°æ®è¿ç§»åˆ†æ

### è¿ç§»æ€§èƒ½
- **æå–é€Ÿåº¦**: {extract.get('record_count', 0) / extract.get('extraction_time', 1):.0f} æ¡/ç§’
- **åŠ è½½é€Ÿåº¦**: {load.get('insertion_rate', 0):.0f} æ¡/ç§’
- **æ•°æ®ä¸€è‡´æ€§**: {'âœ… ä¸€è‡´' if validate.get('data_consistency') else 'âŒ ä¸ä¸€è‡´'}

### è¿ç§»è§„æ¨¡
- **æµ‹è¯•è®°å½•æ•°**: {extract.get('record_count', 0)} æ¡
- **æˆåŠŸè¿ç§»**: {load.get('total_inserted', 0)} æ¡

"""
    
    # æ€»ç»“å’Œå»ºè®®
    md += f"""## æ€»ç»“ä¸å»ºè®®

### æŠ€æœ¯å¯è¡Œæ€§è¯„ä¼°
"""
    
    if summary['passed_tests'] == summary['total_tests']:
        md += """âœ… **æ‰€æœ‰æµ‹è¯•é€šè¿‡** - æŠ€æœ¯å‡çº§æ–¹æ¡ˆå®Œå…¨å¯è¡Œ

### æ¨èå‡çº§è·¯å¾„
1. **ç¬¬ä¸€é˜¶æ®µ**: å‡çº§çˆ¬è™«åˆ°Scrapyæ¡†æ¶
2. **ç¬¬äºŒé˜¶æ®µ**: å¼•å…¥MongoDBä½œä¸ºæ•°æ®å­˜å‚¨
3. **ç¬¬ä¸‰é˜¶æ®µ**: å®Œæˆæ•°æ®è¿ç§»å’Œç³»ç»Ÿä¼˜åŒ–

### é¢„æœŸæ”¶ç›Š
- çˆ¬è™«æ€§èƒ½å’Œç¨³å®šæ€§æ˜¾è‘—æå‡
- æ•°æ®å­˜å‚¨æ›´åŠ çµæ´»å’Œå¯æ‰©å±•
- æ”¯æŒæ›´å¤æ‚çš„æ•°æ®åˆ†æéœ€æ±‚
"""
    elif summary['passed_tests'] > summary['total_tests'] / 2:
        md += """âš ï¸ **éƒ¨åˆ†æµ‹è¯•é€šè¿‡** - æŠ€æœ¯å‡çº§æ–¹æ¡ˆåŸºæœ¬å¯è¡Œï¼Œéœ€è¦è§£å†³éƒ¨åˆ†é—®é¢˜

### å»ºè®®æªæ–½
1. è§£å†³å¤±è´¥æµ‹è¯•ä¸­çš„æŠ€æœ¯é—®é¢˜
2. è¿›è¡Œæ›´è¯¦ç»†çš„æŠ€æœ¯éªŒè¯
3. åˆ¶å®šé£é™©åº”å¯¹æ–¹æ¡ˆ
"""
    else:
        md += """âŒ **å¤šæ•°æµ‹è¯•å¤±è´¥** - å½“å‰æŠ€æœ¯å‡çº§æ–¹æ¡ˆå­˜åœ¨è¾ƒå¤§é£é™©

### å»ºè®®æªæ–½
1. é‡æ–°è¯„ä¼°æŠ€æœ¯é€‰å‹
2. è§£å†³åŸºç¡€ç¯å¢ƒé—®é¢˜
3. è€ƒè™‘æ›¿ä»£æ–¹æ¡ˆ
"""
    
    md += f"""
### ä¸‹ä¸€æ­¥è¡ŒåŠ¨
1. æ ¹æ®æµ‹è¯•ç»“æœè°ƒæ•´å‡çº§æ–¹æ¡ˆ
2. åˆ¶å®šè¯¦ç»†çš„å®æ–½è®¡åˆ’
3. å‡†å¤‡ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

---
*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {results['test_time']}*
"""
    
    return md


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹è¿è¡Œæ¶æ„å‡çº§æŠ€æœ¯éªŒè¯æµ‹è¯•å¥—ä»¶")
    print(f"æµ‹è¯•æ—¶é—´: {datetime.now().isoformat()}")
    
    # è·å–å½“å‰ç›®å½•
    current_dir = os.path.dirname(os.path.abspath(__file__))
    
    # å®šä¹‰æµ‹è¯•è„šæœ¬
    tests = {
        "æ€§èƒ½å¯¹æ¯”æµ‹è¯•": os.path.join(current_dir, "performance_test", "performance_comparison.py"),
        "MongoDBé›†æˆæµ‹è¯•": os.path.join(current_dir, "mongodb_test", "mongodb_integration_test.py"),
        "æ•°æ®è¿ç§»æµ‹è¯•": os.path.join(current_dir, "migration_test", "data_migration_test.py")
    }
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    test_results = {}
    
    for test_name, script_path in tests.items():
        if os.path.exists(script_path):
            test_results[test_name] = run_test_script(script_path, test_name)
        else:
            print(f"âŒ æµ‹è¯•è„šæœ¬ä¸å­˜åœ¨: {script_path}")
            test_results[test_name] = {
                'success': False,
                'error': 'script_not_found'
            }
    
    # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
    report_file = generate_comprehensive_report(test_results)
    
    print(f"\n{'='*60}")
    print("ğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆ!")
    print(f"ğŸ“„ ç»¼åˆæŠ¥å‘Š: {report_file}")
    print(f"{'='*60}")
    
    # æ˜¾ç¤ºç®€è¦ç»“æœ
    passed = sum(1 for r in test_results.values() if r.get('success'))
    total = len(test_results)
    print(f"\nğŸ“Š æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡ ({passed/total*100:.1f}%)")
    
    for test_name, result in test_results.items():
        status = "âœ…" if result.get('success') else "âŒ"
        print(f"  {status} {test_name}")


if __name__ == "__main__":
    main()
